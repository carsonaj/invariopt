{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel, \\\n",
    "RBFKernel, CosineKernel\n",
    "from gpytorch.constraints import Positive\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "Define $\\sigma: \\mathbb{R} \\rightarrow (0, \\infty)$ and $g: \\mathbb{R}^{d \\times n} \\rightarrow \\mathbb{R}^{n \\times n}$ by $$\\sigma(t) = \\frac{e^t}{1+e^t}$$ and $$g(\\theta)_{i,j} = \\sigma[(\\theta^T \\theta)_{i,j}]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "logit = torch.special.logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Implementation:** \n",
    "Let $\\theta \\in \\mathbb{R}^{d \\times n}$. For $t \\in \\{1, \\ldots, T\\}$ and $i,j \\in \\{1, \\ldots, n\\}$, suppose that $A^{(t)}_{i,j} \\overset{\\text{iid}}{\\sim} \\text{Ber}(g(\\theta)_{i,j})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_up_tri_ind(n, offset=0):\n",
    "        ind = torch.triu_indices(row=n, col=n, offset=offset)\n",
    "        \n",
    "        return ind\n",
    "    \n",
    "def get_up_tri(vec, offset=0):\n",
    "    l = vec.shape[-1]\n",
    "    n = int((-1 + (1 + 8*l)**.5)/2)\n",
    "    mat = torch.zeros(n, n)\n",
    "    ind = get_up_tri_ind(n, offset=offset)\n",
    "    mat[ind[0], ind[1]] = vec\n",
    "        \n",
    "    return mat\n",
    "        \n",
    "def get_up_tri_vec(mat, offset=0):\n",
    "    n = mat.shape[-1]\n",
    "    vec = torch.zeros(int(n * (n+1) / 2))\n",
    "    ind = get_up_tri_ind(n, offset=offset)\n",
    "    vec = mat[ind[0], ind[1]]\n",
    "        \n",
    "    return vec\n",
    "\n",
    "class Orbit(torch.nn.Module):\n",
    "    # input:\n",
    "    # eta: 1-dimensional tensor of length l\n",
    "    #      where l = n+1 choose 2\n",
    "    \n",
    "    # output: \n",
    "    # instance of class Orbit identified as a vector in R^l\n",
    "    def __init__(self, eta):\n",
    "        super(Orbit, self).__init__()\n",
    "        # length l\n",
    "        self.l = eta.shape[0]\n",
    "        # embedding dimension n\n",
    "        self.n = int((-1 + (1 + 8*l)**.5)/2)\n",
    "        # vector\n",
    "        self.orb = torch.nn.Parameter(eta)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def neg_avg_log_like(self, A):\n",
    "        t = A.shape[-3]\n",
    "        assert self.n == A.shape[-1]\n",
    "        assert self.n == A.shape[-2]\n",
    "        ind = get_up_tri_ind(self.n, offset=1)\n",
    "        \n",
    "        up_tri = get_up_tri(self.orb)\n",
    "        P = sigmoid(up_tri.t() @ up_tri)\n",
    "        # log likelihood matrix\n",
    "        llm = A*torch.log(P) + (1-A)*torch.log(1-P)\n",
    "        #log likelihood vector\n",
    "        llv = llm[:, ind[0], ind[1]]\n",
    "        # negative average log likelihood\n",
    "        nall = -torch.mean(llv)\n",
    "        \n",
    "        return nall\n",
    "\n",
    "    def forward(self, A):\n",
    "        return self.neg_avg_log_like(A)\n",
    "    \n",
    "    def get_orb_norm(self):\n",
    "        with torch.no_grad():\n",
    "            orb_norm = torch.linalg.norm(self.orb)\n",
    "            \n",
    "        return orb_norm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9678274bb0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed:\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# dimensions\n",
    "n = int(20)\n",
    "l = int(n * (n+1) / 2)\n",
    "d = int(100)\n",
    "t = int(1e3)\n",
    "\n",
    "# generate data\n",
    "sig = .1\n",
    "means = torch.tensor([5.0, -5.0]).reshape((2, 1)).repeat(1, d)\n",
    "stdvs = torch.tensor(sig).repeat(2,d)\n",
    "mix = D.Categorical(torch.ones(2,))\n",
    "comp = D.Independent(D.Normal(means, stdvs), 1)\n",
    "gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "theta0 = gmm.sample((1, n)).reshape((n, d)).t() / torch.tensor(d**.5)\n",
    "\n",
    "ind = get_up_tri_ind(n)\n",
    "r0 = torch.linalg.qr(theta0)[1]\n",
    "eta0 = r0[ind[0], ind[1]]\n",
    "orb0_norm = torch.linalg.norm(eta0)\n",
    "\n",
    "P = sigmoid(theta0.t() @ theta0)\n",
    "P = P.repeat(t, 1, 1)\n",
    "\n",
    "A = torch.bernoulli(P)\n",
    "A[:, ind[0], ind[1]] = 0\n",
    "A = A + torch.transpose(A, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9678274bb0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "negative average log likelihood: 1.143989\n",
      "orbit distance: nan\n",
      "epoch: 1000\n",
      "negative average log likelihood: nan\n",
      "orbit distance: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-e1064c968663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mnall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "\n",
    "# optimizer\n",
    "eta = torch.randn(l)\n",
    "orb = Orbit(eta)\n",
    "opt = torch.optim.SGD(orb.parameters(), lr=1e-2)\n",
    "\n",
    "# likelihoods and distances\n",
    "nalls = []\n",
    "orb_dists = []\n",
    "\n",
    "# optimize\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    opt.zero_grad()\n",
    "    nall = orb(A)\n",
    "    nall.backward()\n",
    "    opt.step() \n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        nalls.append(nall.item())\n",
    "        orb_norm = orb.get_orb_norm() \n",
    "        orb_dist = torch.abs(orb_norm - orb0_norm)\n",
    "        orb_dists.append(orb_dist)\n",
    "        print(\"epoch: %d\" %  epoch)\n",
    "        print(\"negative average log likelihood: %f\" % nall)\n",
    "        print(\"orbit distance: %f\" % orb_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f963cbc5850>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f963caeed90>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f963cb11d30>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.3349)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots\n",
    "plt.plot(nalls)\n",
    "plt.plot(orb_dists)\n",
    "plt.legend(['neg log like', 'orbit distance'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    theta_hat = get_up_tri(orb.orb)\n",
    "\n",
    "P_hat = sigmoid(theta_hat.t() @ theta_hat)\n",
    "\n",
    "torch.linalg.norm(P_hat - P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0_top = torch.randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9678274bb0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5503, -0.1517, -2.4217],\n",
       "        [ 1.5501, -0.0534, -2.1349]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "mix = D.Categorical(torch.ones(2,))\n",
    "comp = D.Independent(D.Normal(torch.randn(2,d), torch.rand(2,d)), 1)\n",
    "gmm = D.MixtureSameFamily(mix, comp)\n",
    "gmm.sample((1, n)).reshape((n, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9678274bb0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-10.1399,  -9.9818],\n",
       "        [ -9.9597, -10.0857],\n",
       "        [ -9.9162,  -9.8899]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "sig = .1\n",
    "means = torch.tensor([10.0, -10.0]).reshape((2, 1)).repeat(1, d)\n",
    "stdvs = torch.tensor(sig).repeat(2,d)\n",
    "mix = D.Categorical(torch.ones(2,))\n",
    "comp = D.Independent(D.Normal(means, stdvs), 1)\n",
    "gmm = D.MixtureSameFamily(mix, comp)\n",
    "\n",
    "gmm.sample((1, n)).reshape((n, d)).t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gmm.sample((1, n)).reshape((n, d)).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10,  10,  10],\n",
       "        [-10, -10, -10]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = torch.tensor([10, -10]).reshape((2, 1)).repeat(1, d)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.distributions.normal.Normal"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.distributions as D\n",
    "D.normal.Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[0, 1],\n",
       "         [1, 0]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8442, 0.5065],\n",
       "        [0.5065, 0.5400]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1693, -0.7062],\n",
       "         [-0.7062, -0.6162]],\n",
       "\n",
       "        [[-1.8593, -0.6802],\n",
       "         [-0.6802, -0.7766]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7062],\n",
       "        [-0.6802]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6932)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1, 0, 0, 1], [0, 1, 1, 0]]).reshape(2, 2, 2)\n",
    "A\n",
    "eta = torch.tensor([1.3, .02, -.4])\n",
    "orb = Orbit(eta)\n",
    "U = get_up_tri(eta)\n",
    "P = sigmoid(U.t() @ U)\n",
    "P\n",
    "llm = A*torch.log(P) + (1-A)*torch.log(1-P)\n",
    "llm\n",
    "ind = get_up_tri_ind(2, offset=1)\n",
    "#log likelihood vector\n",
    "llv = llm[:, ind[0], ind[1]]\n",
    "llv\n",
    "# negative average log likelihood\n",
    "nall = -torch.mean(llv)\n",
    "nall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8592)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(1- .8442))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7428, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,0,0,1], [0,1,1,0,]]).reshape(2, 2, 2)\n",
    "theta = torch.randn(3, 2)\n",
    "orb = Orbit(theta)\n",
    "l = orb.vec.shape[-1]\n",
    "n = int((-1 + (1 + 8*l)**.5)/2)\n",
    "\n",
    "t = A.shape[-3]\n",
    "assert orb.n == A.shape[-1]\n",
    "assert orb.n == A.shape[-2]\n",
    "ind = get_up_tri_ind(n, offset=1)\n",
    "        \n",
    "up_tri = get_up_tri(orb.vec)\n",
    "P = sigmoid(up_tri.t() @ up_tri)\n",
    "# log likelihood matrix\n",
    "llm = A*torch.log(P) + (1-A)*torch.log(1-P)\n",
    "#log likelihood vector\n",
    "llv = llm[:, ind[0], ind[1]]\n",
    "nall = -torch.mean(llv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#orb.vec\n",
    "\n",
    "orb.forward(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0204, -0.3022],\n",
       "         [-0.3022, -0.3985]],\n",
       "\n",
       "        [[-3.9026, -1.3440],\n",
       "         [-1.3440, -1.1127]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3022, -0.3985]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm\n",
    "llm[0:,:][ind[0], ind[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0],\n",
       "         [0, 1]],\n",
       "\n",
       "        [[1, 1],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 1],\n",
       "        [1, 1, 0, 0]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A\n",
    "A.shape[-1:: -1]\n",
    "A.reshape(A.shape[-3], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = torch.randn(2, 5, 3)\n",
    "d = theta.shape[-2]\n",
    "n = theta.shape[-1]\n",
    "assert d >= n\n",
    "        \n",
    "upr_tri = torch.linalg.qr(theta)[1]\n",
    "#upr_tri\n",
    "\n",
    "ind = torch.triu_indices(row=n, col=n, offset=1)\n",
    "x = upr_tri[:, ind[0], ind[1]]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[-1]\n",
    "x.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000],\n",
       "        [0.7311, 0.7311, 0.7311]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "m = torch.zeros(2,3)\n",
    "m[[1], [0, 1, 2]] = torch.tensor([1.0,1.0,1.0])\n",
    "sigmoid(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1407)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1407)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1564,  0.2282,  0.4826,  0.0667, -0.4289, -0.7223, -0.0926,  1.3388,\n",
       "         0.4465])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1564,  0.2282,  0.4826,  0.0667, -0.4289, -0.7223, -0.0926,  1.3388,\n",
       "         0.4465])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = torch.rand(3, 3)\n",
    "X = torch.randn(2, 3, 3)\n",
    "a = X*P\n",
    "torch.sum(X*P) / 18\n",
    "torch.mean((X*P))\n",
    "#X[0,:,:]*P\n",
    "\n",
    "a.shape\n",
    "\n",
    "a.reshape((2, 9))[0]\n",
    "a[0,:,:].reshape((9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparison to MASE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASE: \n",
    "\n",
    "# Vt_hat = d left leading singular vectors of nxd adj matrix At_hat (use torch.linalg.svd)\n",
    "# U_hat = nxtd concatenated Vt_hats\n",
    "# V_hat = d left leading singular vectors of U_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
